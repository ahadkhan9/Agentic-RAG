# LLM Configuration (choose one provider)

# Option 1: Ollama (local, air-gapped)
LLM_PROVIDER=gemini
OLLAMA_MODEL=qwen3:8b

# Option 2: Google Gemini API (cloud)
# LLM_PROVIDER=gemini
GEMINI_MODEL=gemini-3-flash-preview
GOOGLE_API_KEY=

# Embedding Model (runs locally)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Collection Settings
COLLECTION_NAME=manufacturing_docs
CHUNK_SIZE=512
CHUNK_OVERLAP=50
